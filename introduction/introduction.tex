\section{Introduction}

Reservoir Computing (RC) is a form of machine learning that sprang out from the study of recurrent neural networks (RNNs).
In short, it utilizes the dynamics of some complex system dubbed a 'reservoir' to preprocess a timeseries problem,
transforming it from a temporal to a spacial one in the reservoir, making it then separable with a usually simple readout layer.

In this paper the dynamics of Reservoir Computing systems where the reservoir is a Random Boolean Network (RBN) \cite{gershenson2004introduction} is investigated.
In \cite{rbn-reservoir} RBN Reservoir Computing systems (RRC) were investigated,
and found to be a fruitful approach.
A computational system consisting of such simple nodes with inherent emergent properties
are an interesting field of study as an alternative to classical computation.
The study of such networks can also pave the way for selecting physical substrates as reservoirs.

First we create a working RBN Reservoir Computing system in the Python programming language,
reproducing chosen experiments from \cite{rbn-reservoir}.
These include finding the optimal input connectivity ($L$) and internal connectivity $K$,
as well as testing their measure of Computational Capability against actual reservoir performance.

Next we investigate whether the readout layer of a working RRC system can be re-used with other RBN-reservoirs than the one it was originally trained on,
and still stay accurate on the original classification task.
These functionally equivalent reservoirs, if any, will be evolved through the use of a genetic algorithm (GA).

Finally we look at the dynamics and characteristics of these groups of RBN Reservoirs,
attempting to find any similarities that made them exploitable for computation.
